{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Enron Fraud"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Initital Load\n",
    "### Import packages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pandas import DataFrame\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import Imputer\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "sys.path.append(\"../tools/\")\n",
    "%matplotlib inline\n",
    "from feature_format import featureFormat, targetFeatureSplit\n",
    "from tester import dump_classifier_and_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset and create dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features_email = ['to_messages', 'from_messages',  'from_poi_to_this_person',\n",
    "           'from_this_person_to_poi', 'shared_receipt_with_poi']\n",
    "# finance data\n",
    "features_finance = ['salary', 'bonus', 'long_term_incentive', 'deferred_income',\n",
    "             'deferral_payments', 'loan_advances', 'other', 'expenses',\n",
    "             'director_fees', 'total_payments',\n",
    "             'exercised_stock_options', 'restricted_stock',\n",
    "             'restricted_stock_deferred', 'total_stock_value']\n",
    "# all features\n",
    "features_list = features_email + features_finance\n",
    "# all features column names\n",
    "features_column_names = ['poi'] + ['email_address'] + features_email + features_finance\n",
    "# all features data type\n",
    "features_dtype = [bool] + [str] + list(np.repeat(float, 19))\n",
    "\n",
    "### Load the dictionary containing the dataset\n",
    "with open(\"final_project_dataset.pkl\", \"r\") as data_file:\n",
    "    data_dict = pickle.load(data_file)\n",
    "\n",
    "# converting the data into a data frame\n",
    "df = DataFrame.from_dict(data_dict, orient='index')\n",
    "\n",
    "# reordering the columns\n",
    "df = df.loc[:, features_column_names]\n",
    "\n",
    "# converting the data type\n",
    "for i in xrange(len(features_column_names)):\n",
    "    df[features_column_names[i]] = df[features_column_names[i]].astype(features_dtype[i], errors='ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "### Add ratios of email & receipt sharing with poi's to df\n",
    "The ratio of emails send/recieved to/by pois compared to all emails that were send. The total amount of mails send by pois"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# calculate ratio\n",
    "df['recieved_from_poi_ratio'] = df['from_poi_to_this_person'] / df['to_messages']\n",
    "df['sent_to_poi_ratio'] = df['from_this_person_to_poi'] / df['from_messages']\n",
    "df['shared_receipt_with_poi_ratio'] = df['shared_receipt_with_poi'] / df['to_messages']\n",
    "# add labels to df\n",
    "features_email_new = ['recieved_from_poi_ratio', 'sent_to_poi_ratio', 'shared_receipt_with_poi_ratio']\n",
    "features_all = features_list + features_email_new"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive analysis & wrangling of dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Shape of the table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#Dataset Shape:\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The shape of the dataset shows that there are 146 rows (humans) and 24 columns (features) of which three are ratio that were added in the last section."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Missing features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_null_value_ratio = (df.isnull().sum() / df.shape[0]).sort_values(ascending=False)\n",
    "df_null_values = (df.isnull().sum()).sort_values(ascending=False)\n",
    "frames = [df_null_value_ratio, df_null_value_ratio]\n",
    "print pd.concat(frames, axis=1, join_axes=[df1.index])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is good news! Even though there are a bunch of features missing, there is a poi flag and email address for each person in the dataset. There are 18 pois that make 14% of the total dataset.\n",
    "\n",
    "### POIs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# name of persons in dataset\n",
    "people = data_dict.keys()\n",
    "print('Total persons in dataset: %d' % len(people))\n",
    "# count number of pois\n",
    "POI_count = 0\n",
    "for person in people:\n",
    "    POI_count += data_dict[person]['poi']\n",
    "# print pois\n",
    "print('Number of POIs: %d' % POI_count)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "POI's only make up for 14% of our dataset which is a skewed distribution that needs to be considered when evaluating the classification algos. If an algo such as POI = False would be deployed the accuracy would already be at 86%. Developing an algorithm with a accurady of 86% in less than 5 minutes does not sound too bad â€“ but doesn't help in identifying the POIs at all."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Positional Parameters\n",
    "Defined as outliers above Q3 + 1.5 IQR and Q3 + 3 IQR, respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Outlier Confirmation [Before data modification]\n",
    "# sns.distplot(df['to_messages'].dropna())\n",
    "sns.distplot(df['from_messages'].dropna())\n",
    "# plt.hist(df['from_messages'].dropna())\n",
    "# print df[df['from_messages'] > 2800]\n",
    "# \n",
    "# plt.hist(df['from_poi_to_this_person'].dropna())\n",
    "# print df[df['from_poi_to_this_person'] > 500]\n",
    "# \n",
    "# plt.hist(df['from_this_person_to_poi'].dropna())\n",
    "# print df[df['from_this_person_to_poi'] > 300]\n",
    "# \n",
    "# plt.hist(df['shared_receipt_with_poi'].dropna())\n",
    "# print df[df['shared_receipt_with_poi'] > 4000]\n",
    "# \n",
    "# plt.hist(df['salary'])\n",
    "# print df[df['salary'] > 2.4e+07]\n",
    "# # -> [Modification] \"TOTAL\" is an invalid data point\n",
    "# print df[df['salary'] > 1.0e+06]\n",
    "# \n",
    "# plt.hist(df['bonus'])\n",
    "# print df[df['bonus'] > 4.0e+06]\n",
    "# \n",
    "# plt.hist(df['long_term_incentive'])\n",
    "# print df[df['long_term_incentive'] > 2.0e+06]\n",
    "# \n",
    "# plt.hist(df['deferred_income'])\n",
    "# print df[df['deferred_income'] < -2.8e+06]\n",
    "# print df['deferred_income'][df['deferred_income'] < -2.8e+06]\n",
    "# \n",
    "# plt.hist(df['deferral_payments'])\n",
    "# print df[df['deferral_payments'] < 0]\n",
    "# # -> [Modification] BELFER ROBERT - miss-alignment of columns\n",
    "# print df[df['deferral_payments'] > 5.7e+06]\n",
    "# \n",
    "# plt.hist(df['loan_advances'])\n",
    "# print df[df['loan_advances'] > 7.3e+07]\n",
    "# plt.hist(df.loc[df['loan_advances'] < 7.3e+07, 'loan_advances'])\n",
    "# print df[df['loan_advances'] > 4.0e+04]\n",
    "# plt.hist(df.loc[df['loan_advances'] < 4.0e+04, 'loan_advances'])\n",
    "# print sum(df['loan_advances'][df['loan_advances'] < 4.0e+04])\n",
    "# # -> Only few people took loan advances, most of them are 0.\n",
    "# \n",
    "# plt.hist(df['other'])\n",
    "# print df[df['other'] > 7.0e+06]\n",
    "# \n",
    "# plt.hist(df['expenses'])\n",
    "# print df[df['expenses'] > 1.37e+05]\n",
    "# \n",
    "# plt.hist(df['director_fees'])\n",
    "# print df[df['director_fees'] > 1.0e+05]\n",
    "# \n",
    "# plt.hist(df['total_payments'])\n",
    "# print df[df['total_payments'] > 9.3e+07]\n",
    "# \n",
    "# plt.hist(df['exercised_stock_options'])\n",
    "# print df[df['exercised_stock_options'] > 2.7e+07]\n",
    "# \n",
    "# plt.hist(df['restricted_stock'])\n",
    "# print df[df['restricted_stock'] < 0]\n",
    "# # -> [Modification] BHATNAGAR SANJAY - miss-alignment of columns\n",
    "# print df[df['restricted_stock'] > 1.3e+07]\n",
    "# \n",
    "# plt.hist(df['restricted_stock_deferred'])\n",
    "# print df[df['restricted_stock_deferred'] < -1.5e+06]\n",
    "# \n",
    "# plt.hist(df['total_stock_value'])\n",
    "# print df[df['total_stock_value'] > 2.4e+07]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Outlier Confirmation [Before data modification]\n",
    "\n",
    "sns.distplot(df['to_messages'].dropna())\n",
    "median = df['to_messages'].median()\n",
    "iqr = df['to_messages'].quantile(0.75) - median\n",
    "outliers = median + 1.5 * iqr\n",
    "extreme_values = median + 3 * iqr\n",
    "print df[df['to_messages'] > outliers]\n",
    "print df[df['to_messages'] > extreme_values]\n",
    "# print df[df['to_messages'] > 4500]\n",
    "# print df[df['to_messages'] > 10000]\n",
    "# \n",
    "# plt.hist(df['from_messages'].dropna())\n",
    "# print df[df['from_messages'] > 2800]\n",
    "# \n",
    "# plt.hist(df['from_poi_to_this_person'].dropna())\n",
    "# print df[df['from_poi_to_this_person'] > 500]\n",
    "# \n",
    "# plt.hist(df['from_this_person_to_poi'].dropna())\n",
    "# print df[df['from_this_person_to_poi'] > 300]\n",
    "# \n",
    "# plt.hist(df['shared_receipt_with_poi'].dropna())\n",
    "# print df[df['shared_receipt_with_poi'] > 4000]\n",
    "# \n",
    "# plt.hist(df['salary'])\n",
    "# print df[df['salary'] > 2.4e+07]\n",
    "# # -> [Modification] \"TOTAL\" is an invalid data point\n",
    "# print df[df['salary'] > 1.0e+06]\n",
    "# \n",
    "# plt.hist(df['bonus'])\n",
    "# print df[df['bonus'] > 4.0e+06]\n",
    "# \n",
    "# plt.hist(df['long_term_incentive'])\n",
    "# print df[df['long_term_incentive'] > 2.0e+06]\n",
    "# \n",
    "# plt.hist(df['deferred_income'])\n",
    "# print df[df['deferred_income'] < -2.8e+06]\n",
    "# print df['deferred_income'][df['deferred_income'] < -2.8e+06]\n",
    "# \n",
    "# plt.hist(df['deferral_payments'])\n",
    "# print df[df['deferral_payments'] < 0]\n",
    "# # -> [Modification] BELFER ROBERT - miss-alignment of columns\n",
    "# print df[df['deferral_payments'] > 5.7e+06]\n",
    "# \n",
    "# plt.hist(df['loan_advances'])\n",
    "# print df[df['loan_advances'] > 7.3e+07]\n",
    "# plt.hist(df.loc[df['loan_advances'] < 7.3e+07, 'loan_advances'])\n",
    "# print df[df['loan_advances'] > 4.0e+04]\n",
    "# plt.hist(df.loc[df['loan_advances'] < 4.0e+04, 'loan_advances'])\n",
    "# print sum(df['loan_advances'][df['loan_advances'] < 4.0e+04])\n",
    "# # -> Only few people took loan advances, most of them are 0.\n",
    "# \n",
    "# plt.hist(df['other'])\n",
    "# print df[df['other'] > 7.0e+06]\n",
    "# \n",
    "# plt.hist(df['expenses'])\n",
    "# print df[df['expenses'] > 1.37e+05]\n",
    "# \n",
    "# plt.hist(df['director_fees'])\n",
    "# print df[df['director_fees'] > 1.0e+05]\n",
    "# \n",
    "# plt.hist(df['total_payments'])\n",
    "# print df[df['total_payments'] > 9.3e+07]\n",
    "# \n",
    "# plt.hist(df['exercised_stock_options'])\n",
    "# print df[df['exercised_stock_options'] > 2.7e+07]\n",
    "# \n",
    "# plt.hist(df['restricted_stock'])\n",
    "# print df[df['restricted_stock'] < 0]\n",
    "# # -> [Modification] BHATNAGAR SANJAY - miss-alignment of columns\n",
    "# print df[df['restricted_stock'] > 1.3e+07]\n",
    "# \n",
    "# plt.hist(df['restricted_stock_deferred'])\n",
    "# print df[df['restricted_stock_deferred'] < -1.5e+06]\n",
    "# \n",
    "# plt.hist(df['total_stock_value'])\n",
    "# print df[df['total_stock_value'] > 2.4e+07]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Outlier Confirmation [Before data modification]\n",
    "\n",
    "sns.distplot(df['to_messages'].dropna())\n",
    "median = df['to_messages'].median()\n",
    "iqr = df['to_messages'].quantile(0.75) - median\n",
    "outliers = median + 1.5 * iqr\n",
    "extreme_values = median + 3 * iqr\n",
    "print df[df['to_messages'] > outliers]\n",
    "print df[df['to_messages'] > extreme_values]\n",
    "# print df[df['to_messages'] > 4500]\n",
    "# print df[df['to_messages'] > 10000]\n",
    "# \n",
    "# plt.hist(df['from_messages'].dropna())\n",
    "# print df[df['from_messages'] > 2800]\n",
    "# \n",
    "# plt.hist(df['from_poi_to_this_person'].dropna())\n",
    "# print df[df['from_poi_to_this_person'] > 500]\n",
    "# \n",
    "# plt.hist(df['from_this_person_to_poi'].dropna())\n",
    "# print df[df['from_this_person_to_poi'] > 300]\n",
    "# \n",
    "# plt.hist(df['shared_receipt_with_poi'].dropna())\n",
    "# print df[df['shared_receipt_with_poi'] > 4000]\n",
    "# \n",
    "# plt.hist(df['salary'])\n",
    "# print df[df['salary'] > 2.4e+07]\n",
    "# # -> [Modification] \"TOTAL\" is an invalid data point\n",
    "# print df[df['salary'] > 1.0e+06]\n",
    "# \n",
    "# plt.hist(df['bonus'])\n",
    "# print df[df['bonus'] > 4.0e+06]\n",
    "# \n",
    "# plt.hist(df['long_term_incentive'])\n",
    "# print df[df['long_term_incentive'] > 2.0e+06]\n",
    "# \n",
    "# plt.hist(df['deferred_income'])\n",
    "# print df[df['deferred_income'] < -2.8e+06]\n",
    "# print df['deferred_income'][df['deferred_income'] < -2.8e+06]\n",
    "# \n",
    "# plt.hist(df['deferral_payments'])\n",
    "# print df[df['deferral_payments'] < 0]\n",
    "# # -> [Modification] BELFER ROBERT - miss-alignment of columns\n",
    "# print df[df['deferral_payments'] > 5.7e+06]\n",
    "# \n",
    "# plt.hist(df['loan_advances'])\n",
    "# print df[df['loan_advances'] > 7.3e+07]\n",
    "# plt.hist(df.loc[df['loan_advances'] < 7.3e+07, 'loan_advances'])\n",
    "# print df[df['loan_advances'] > 4.0e+04]\n",
    "# plt.hist(df.loc[df['loan_advances'] < 4.0e+04, 'loan_advances'])\n",
    "# print sum(df['loan_advances'][df['loan_advances'] < 4.0e+04])\n",
    "# # -> Only few people took loan advances, most of them are 0.\n",
    "# \n",
    "# plt.hist(df['other'])\n",
    "# print df[df['other'] > 7.0e+06]\n",
    "# \n",
    "# plt.hist(df['expenses'])\n",
    "# print df[df['expenses'] > 1.37e+05]\n",
    "# \n",
    "# plt.hist(df['director_fees'])\n",
    "# print df[df['director_fees'] > 1.0e+05]\n",
    "# \n",
    "# plt.hist(df['total_payments'])\n",
    "# print df[df['total_payments'] > 9.3e+07]\n",
    "# \n",
    "# plt.hist(df['exercised_stock_options'])\n",
    "# print df[df['exercised_stock_options'] > 2.7e+07]\n",
    "# \n",
    "# plt.hist(df['restricted_stock'])\n",
    "# print df[df['restricted_stock'] < 0]\n",
    "# # -> [Modification] BHATNAGAR SANJAY - miss-alignment of columns\n",
    "# print df[df['restricted_stock'] > 1.3e+07]\n",
    "# \n",
    "# plt.hist(df['restricted_stock_deferred'])\n",
    "# print df[df['restricted_stock_deferred'] < -1.5e+06]\n",
    "# \n",
    "# plt.hist(df['total_stock_value'])\n",
    "# print df[df['total_stock_value'] > 2.4e+07]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlation coefficients:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "print df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "### Articles\n",
    "* A look at those involved in the Enron scandal, USA Today - http://usatoday30.usatoday.com/money/industries/energy/2005-12-28-enron-participants_x.htm\n",
    "* The Immortal Life of the Enron E-mails, MIT Technology Review - https://www.technologyreview.com/s/515801/the-immortal-life-of-the-enron-e-mails/\n",
    "* Implementing a Weighted Majority Rule Ensemble Classifier in scikit-learn, Sebastian Raschka - http://sebastianraschka.com/Articles/2014_ensemble_classifier.html\n",
    "* Color Palettes in Seaborn, Chris Albon - http://chrisalbon.com/python/seaborn_color_palettes.html\n",
    "* Random Forests, Leo Breiman and Adele Cutler - http://www.stat.berkeley.edu/~breiman/RandomForests/cc_home.htm\n",
    "* Python sklearn.feature_selection.f_classif Examples - http://www.programcreek.com/python/example/85917/sklearn.feature_selection.f_classif\n",
    "\n",
    "### Cheatsheets\n",
    "* Markdown - https://github.com/adam-p/markdown-here/wiki/Markdown-Cheatsheet\n",
    "* Pandas - https://github.com/pandas-dev/pandas/blob/master/doc/cheatsheet/Pandas_Cheat_Sheet.pdf\n",
    "* Numpy - https://s3.amazonaws.com/assets.datacamp.com/blog_assets/Numpy_Python_Cheat_Sheet.pdf\n",
    "\n",
    "### Documentation\n",
    "* Pipelining: chaining a PCA and a logistic regression, scikit learn - http://scikit-learn.org/stable/auto_examples/plot_digits_pipe.html\n",
    "* matplotlib.axes, matplotlib - http://matplotlib.org/api/axes_api.html\n",
    "* DataFrame quantiles, pandas - http://pandas.pydata.org/pandas-docs/version/0.17.0/generated/pandas.DataFrame.quantile.html\n",
    "* Visualization, pandas - https://pandas.pydata.org/pandas-docs/stable/visualization.html\n",
    "* pyplot, matplotlib - https://matplotlib.org/devdocs/api/_as_gen/matplotlib.pyplot.hist.html\n",
    "* sort values, pandas - https://pandas.pydata.org/pandas-docs/stable/generated/pandas.DataFrame.sort_values.html  \n",
    "\n",
    "### GitHub Repositories\n",
    "* EnsembleVoteClassifier, Sebastian Raschka - http://rasbt.github.io/mlxtend/user_guide/classifier/EnsembleVoteClassifier/\n",
    "* Grace Pehl: Identifying Persons of Interest from the Enron Corpus - https://github.com/grace-pehl/enron\n",
    "* brandjamie: Marchine Learning with the enron emails dataset - https://github.com/brandjamie/udacity_enron\n",
    "* Daria ALekseeva: Enron Dataset - https://github.com/DariaAlekseeva/Enron_Dataset\n",
    "* watanabe8760: uda-da-p5-enron-fraud-detection - https://github.com/watanabe8760/uda-da-p5-enron-fraud-detection\n",
    "* Mayukh Sobo: Enron Fraud https://github.com/MayukhSobo/EnronFraud \n",
    "\n",
    "### Q&A pages\n",
    "* Pandas Replacement for .ix, Stack Overflow  - https://stackoverflow.com/questions/43838999/pandas-replacement-for-ix\n",
    "* Sci-kit and Regression Summary, Stack Overflow - http://stackoverflow.com/questions/26319259/sci-kit-and-regression-summary\n",
    "* How to obtain True Positive, True Negative, False Positive and False Negative, Stack Overflow - https://stackoverflow.com/questions/31324218/scikit-learn-how-to-obtain-true-positive-true-negative-false-positive-and-fal\n",
    "* Why do we need to normalize data before analysis, Cross Validated - http://stats.stackexchange.com/questions/69157/why-do-we-need-to-normalize-data-before-analysis\n",
    "* Perform feature normalization before or within model validation?, Cross Validated - http://stats.stackexchange.com/questions/77350/perform-feature-normalization-before-or-within-model-validation\n",
    "* How should the interquartile range be calculated in Python?, Stack Overflow - http://stackoverflow.com/questions/27472330/how-should-the-interquartile-range-be-calculated-in-python\n",
    "* scikit learn svc coef0 parameter range, Stack Overflow - http://stackoverflow.com/questions/21390570/scikit-learn-svc-coef0-parameter-range\n",
    "* What is a good range of values for the svm.SVC() hyperparameters to be explored via GridSearchCV()?, Stack Overflow - http://stackoverflow.com/questions/26337403/what-is-a-good-range-of-values-for-the-svm-svc-hyperparameters-to-be-explored\n",
    "* Imputation before or after splitting into train and test?, Cross Validated - http://stats.stackexchange.com/questions/95083/imputation-before-or-after-splitting-into-train-and-test\n",
    "* Is there a rule-of-thumb for how to divide a dataset into training and validation sets?, Stack Overflow - http://stackoverflow.com/questions/13610074/is-there-a-rule-of-thumb-for-how-to-divide-a-dataset-into-training-and-validatio\n",
    "* What is the difference between test set and validation set?, Cross Validated - http://stats.stackexchange.com/questions/19048/what-is-the-difference-between-test-set-and-validation-set\n",
    "* Python - What is exactly sklearn.pipeline.Pipeline?, Stack Overflow - http://stackoverflow.com/questions/33091376/python-what-is-exactly-sklearn-pipeline-pipeline\n",
    "* How can I use a custom feature selection function in scikit-learn's pipeline, Stack Overflow - http://stackoverflow.com/questions/25250654/how-can-i-use-a-custom-feature-selection-function-in-scikit-learns-pipeline\n",
    "* Seaborn distplot y-axis normalisation wrong ticklabels, Stack Overflow - http://stackoverflow.com/questions/32274865/seaborn-distplot-y-axis-normalisation-wrong-ticklabels\n",
    "* How to save a Seaborn plot into a file, Stack Overflow - http://stackoverflow.com/questions/32244753/how-to-save-a-seaborn-plot-into-a-file\n",
    "* Seaborn plots not showing up, Stack Overflow - https://stackoverflow.com/questions/26597116/seaborn-plots-not-showing-up\n",
    "\n",
    "### Tools\n",
    "* Markdown Tables Generator - http://www.tablesgenerator.com/markdown_tables\n",
    "* JSON pretty print - http://jsonprettyprint.com\n",
    "\n",
    "### Wikipedia\n",
    "* Enron scandal - https://en.wikipedia.org/wiki/Enron_scandal\n",
    "* Boxplots - https://en.wikipedia.org/wiki/Box_plot\n",
    "* Interquartile range - https://en.wikipedia.org/wiki/Interquartile_range\n",
    "* False positive rate - https://en.wikipedia.org/wiki/False_positive_rate\n",
    "* False discovery rate - https://en.wikipedia.org/wiki/False_discovery_rate\n",
    "* Precision and recall - https://en.wikipedia.org/wiki/Precision_and_recall"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
